Loading input
Done
Preprocessing for gradient
Done
before training:  2015-04-24 08:52:50.945188
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] cost params
--------------------------------------------------
Traceback (most recent call last):
  File "/home/pratheek/work/memm/pyspark/memm_pyspark.py", line 411, in <module>
    params = mymin(cost1, param, method = 'L-BFGS-B', jac = gradient1_new, options = {'maxiter':100}) #, jac = self.gradient) # , options = {'maxiter':100}
  File "/usr/lib/python2.7/site-packages/scipy/optimize/_minimize.py", line 427, in minimize
    callback=callback, **options)
  File "/usr/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py", line 315, in _minimize_lbfgsb
    f, g = func_and_grad(x)
  File "/usr/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py", line 266, in func_and_grad
    f = fun(x, *args)
  File "/usr/lib/python2.7/site-packages/scipy/optimize/optimize.py", line 282, in function_wrapper
    return function(*(wrapper_args + args))
  File "/home/pratheek/work/memm/pyspark/memm_pyspark.py", line 284, in cost1
    expected,emperical = distributed_input_data.map(helper).reduce(lambda x,y:(x[0]+y[0],x[1]+y[1]))
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/pyspark/rdd.py", line 740, in reduce
    vals = self.mapPartitions(func).collect()
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/pyspark/rdd.py", line 701, in collect
    bytesInJava = self._jrdd.collect().iterator()
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py", line 536, in __call__
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py", line 364, in send_command
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py", line 473, in send_command
  File "/usr/lib/python2.7/socket.py", line 430, in readline
    data = recv(1)
KeyboardInterrupt
