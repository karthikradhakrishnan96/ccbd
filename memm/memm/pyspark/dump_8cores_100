Loading input
Done
Preprocessing for gradient
Done
before training:  2015-04-24 02:57:10.782230
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] cost params
--------------------------------------------------
8593.27626462 8593.27626462 0.0
--------------------------------------------------
233.0 9.34285714286
95.0 95.0
114.0 13.4571428571
Traceback (most recent call last):
  File "/home/pratheek/work/memm/pyspark/memm_pyspark.py", line 411, in <module>
    params = mymin(cost1, param, method = 'L-BFGS-B', jac = gradient1_new, options = {'maxiter':100}) #, jac = self.gradient) # , options = {'maxiter':100}
  File "/usr/lib/python2.7/site-packages/scipy/optimize/_minimize.py", line 427, in minimize
    callback=callback, **options)
  File "/usr/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py", line 315, in _minimize_lbfgsb
    f, g = func_and_grad(x)
  File "/usr/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py", line 267, in func_and_grad
    g = jac(x, *args)
  File "/home/pratheek/work/memm/pyspark/memm_pyspark.py", line 366, in gradient1_new
    expected = distributed_input_data.map(helper).reduce(lambda x,y:x+y)
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/pyspark/rdd.py", line 740, in reduce
    vals = self.mapPartitions(func).collect()
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/pyspark/rdd.py", line 701, in collect
    bytesInJava = self._jrdd.collect().iterator()
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py", line 536, in __call__
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py", line 364, in send_command
  File "/home/pratheek/work/spark-1.3.0-bin-hadoop2.4/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py", line 473, in send_command
  File "/usr/lib/python2.7/socket.py", line 430, in readline
    data = recv(1)
KeyboardInterrupt
